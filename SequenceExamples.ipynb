{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {'seqs_file': 4,\n",
    "           'max_v': 6,\n",
    "           'max_t': 5,\n",
    "           'n_codes': 7,\n",
    "           'n_labels': 4,\n",
    "           'seqs_file': 'seqs',\n",
    "           'labels_file': 'labs',\n",
    "           'demo_file': 'demo',\n",
    "           'out_file': 'zipped_TFR',\n",
    "           'n_patients': 4}\n",
    "args = Namespace(**options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(args=args):\n",
    "    \"\"\"Replace later with dataset stuff.\"\"\"\n",
    "    seqs_file = args.seqs_file\n",
    "    if args.labels_file is not None:\n",
    "        labels_file = args.labels_file\n",
    "    seqs = pickle.load(open(seqs_file, 'rb'))\n",
    "    labs = None\n",
    "    if args.labels_file is not None:\n",
    "        labels_file = args.labels_file\n",
    "        labs = pickle.load(open(labels_file, 'rb'))\n",
    "    D_t = None\n",
    "    demo_dim = 0\n",
    "    if args.demo_file is not None:\n",
    "        demo_file = args.demo_file\n",
    "        D_t = pickle.load(open(demo_file, 'rb'))\n",
    "        demo_dim = D_t.shape[-1]\n",
    "        demo = tf.constant(D_t, dtype=tf.float32)\n",
    "        demo = tf.reshape(demo, [args.n_patients, -1])\n",
    "    return seqs, labs, demo, demo_dim\n",
    "\n",
    "\n",
    "def fill_visit(visit, args=args):\n",
    "    \"\"\"Fill all deficit visits with -2.\n",
    "\n",
    "    Ensure that all visits have the same number of ICDs for efficient\n",
    "    tensor logic. If a visit has fewer ICDs, filler ICDs get one-hot\n",
    "    encoded as the zero vector, so that they affect nothing.\n",
    "\n",
    "    visit: a list of integer medical codes\n",
    "\n",
    "    Note: No visit in training or testing should have more than max_v\n",
    "          visits.\n",
    "    \"\"\"\n",
    "    max_v = args.max_v\n",
    "    if visit != [-1]:\n",
    "        new_visit = []\n",
    "        new_visit.extend(visit)\n",
    "        n_icd = len(visit)\n",
    "        deficit = max_v - n_icd\n",
    "        new_visit.extend([-2] * deficit)\n",
    "        return new_visit\n",
    "\n",
    "\n",
    "def fill_patient(patient, mask_batch, args=args):\n",
    "    \"\"\"Ensure that all patients have max_t visits.\n",
    "\n",
    "    Create visits full of -2s, which are one-hot encoded as zero\n",
    "    vectors. This makes all patients commensurate for efficient tensor\n",
    "    logic.\n",
    "\n",
    "    patient: list of list of integer codes\n",
    "    max_t: the number of visits all patients ought to have\n",
    "\n",
    "    Note: No patient in training or test data should have more\n",
    "          than max_t visits.\n",
    "    \"\"\"\n",
    "    max_t = args.max_t\n",
    "    max_v = args.max_v\n",
    "    new_patient = []\n",
    "    new_patient.extend(patient)\n",
    "    new_mask_batch = mask_batch\n",
    "    t = len(new_patient)\n",
    "    deficit = (max_t - t)\n",
    "    new_patient.extend([[-2] * max_v] * deficit)\n",
    "    new_mask_batch.append([[0] * max_v] * deficit)\n",
    "    return new_patient, new_mask_batch, t\n",
    "\n",
    "\n",
    "def tensorize_seqs(seqs, args=args, true_seqs=True):\n",
    "    \"\"\"Convert med2vec to tensorflow data.\n",
    "\n",
    "    seqs: list of list. cf  https://github.com/mp2893/med2vec\n",
    "    true_seqs: bool. Are we tensorizing the true sequences? If false,\n",
    "               we are tonsorizing labels.\n",
    "    returns:\n",
    "        patients: tensor with shape [patients, max_t, max_v, |C|]\n",
    "                  or [patients, max_t, max_v, n_labels] if true_seqs is\n",
    "                  False.\n",
    "        row_masks: numpy array with shape [patients, max_t, max_v]\n",
    "               Later, we will create a [patients, max_t, max_v, |C|]\n",
    "               tensor where the [p, t, i, j] entry is p(c_j|c_i).\n",
    "               Row_masks will drop the rows where c_i is the zero\n",
    "               vector--that is, an NA ICD.\n",
    "\n",
    "               A separate mask, col_mask, will be created from\n",
    "               patients in order to mask, for each t, those j for\n",
    "               which c_j did not appear in visit t, as well as\n",
    "               p(c_i|c_i).\n",
    "\n",
    "               The masks are to be applied in reverse order of creation.\n",
    "               col_mask is applied with tf.multiply and row_masks\n",
    "               with tf.boolean_mask to avoid needless reshaping.\n",
    "        patients_ts: numpy array with shape [patients,] containing the\n",
    "                     number of true visits for each patient.\n",
    "    \"\"\"\n",
    "    patients = []\n",
    "    new_patient = []\n",
    "    row_masks = []\n",
    "    mask_batch = []\n",
    "    patients_ts = []\n",
    "    for visit in seqs + [[-1]]:\n",
    "        if visit != [-1]:\n",
    "            visit = fill_visit(visit, args)\n",
    "            new_patient.append(visit)\n",
    "        else:\n",
    "            new_patient, mask_batch, t = fill_patient(new_patient,\n",
    "                                                      mask_batch,\n",
    "                                                      args)\n",
    "            patients.append(new_patient)\n",
    "            if true_seqs:\n",
    "                patients_ts.append(t)\n",
    "                row_masks.append(mask_batch)\n",
    "                mask_batch = []\n",
    "            new_patient = []\n",
    "    patients = tf.constant(patients)\n",
    "    patients_ts = patients_ts\n",
    "    #patients_ts = tf.expand_dims(patients_ts, -1)\n",
    "    #patients_ts = tf.expand_dims(patients_ts, -1)\n",
    "    row_masks = tf.not_equal(patients, -2)\n",
    "    row_masks = tf.cast(row_masks, tf.int32)\n",
    "    patients = tf.reshape(patients, [args.n_patients, -1])\n",
    "    row_masks = tf.reshape(row_masks, [args.n_patients, -1])\n",
    "    return patients, row_masks, patients_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs, labs, demo, demo_dim = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients, row_masks, patients_ts = tensorize_seqs(seqs, true_seqs=True)\n",
    "labels, _, _ = tensorize_seqs(labs, true_seqs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tf.data.Dataset().from_tensor_slices((patients,\n",
    "    labels,\n",
    "    demo,\n",
    "    row_masks,\n",
    "    patients_ts\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_it = output.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#serial = output.map(lambda v,w,x,y,z: (tf.serialize_tensor(v),tf.serialize_tensor(w),tf.serialize_tensor(x),tf.serialize_tensor(y),z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_example(patient, label, demo, row_mask, patient_t, args=args):\n",
    "    # The object we return\n",
    "    ex = tf.train.SequenceExample()\n",
    "    # A non-sequential feature of our example\n",
    "    ex.context.feature[\"patient_t\"].int64_list.value.append(patient_t)\n",
    "    ex.context.feature[\"max_t\"].int64_list.value.append(args.max_t)\n",
    "    ex.context.feature[\"max_v\"].int64_list.value.append(args.max_v)\n",
    "    # Feature lists for the two sequential features of our example\n",
    "    fl_patients = ex.feature_lists.feature_list[\"patient\"]\n",
    "    fl_labels = ex.feature_lists.feature_list[\"label\"]\n",
    "    fl_demo = ex.feature_lists.feature_list[\"demo\"]\n",
    "    fl_row_masks = ex.feature_lists.feature_list[\"row_mask\"]\n",
    "    for visit, lab, dem, mask in zip(patient, label, demo, row_mask):\n",
    "        fl_patients.feature.add().int64_list.value.append(visit)\n",
    "        fl_labels.feature.add().int64_list.value.append(lab)\n",
    "        fl_demo.feature.add().float_list.value.append(dem)\n",
    "        fl_row_masks.feature.add().int64_list.value.append(mask)\n",
    "    return ex.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_serialize_w_labels(patient, label, demo, row_mask, patient_t):\n",
    "    \"\"\"Map serialize_with_labels to tf.data.Dataset.\"\"\"\n",
    "    tf_string = tf.py_func(make_example,\n",
    "                           (patient, label, demo, row_mask, patient_t),\n",
    "                           tf.string)\n",
    "    return tf.reshape(tf_string, ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialized = output.map(tf_serialize_w_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialized_it = serialized.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = sess.run(serialized_it.get_next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.contrib.data.TFRecordWriter(args.out_file)\n",
    "writeop = writer.write(serialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(writeop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = tf.data.TFRecordDataset([args.out_file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_it = raw.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = sess.run(raw_it.get_next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sequence_examples(example_proto, args=args):\n",
    "    ctxt_fts = {\n",
    "        \"patient_t\": tf.FixedLenFeature([], dtype=tf.int64),\n",
    "        \"max_t\": tf.FixedLenFeature([], dtype=tf.int64),\n",
    "        \"max_v\": tf.FixedLenFeature([], dtype=tf.int64),\n",
    "    }\n",
    "    seq_fts = {\n",
    "        \"patient\": tf.FixedLenSequenceFeature([], dtype=tf.int64),\n",
    "        \"label\": tf.FixedLenSequenceFeature([], dtype=tf.int64),\n",
    "        \"demo\": tf.FixedLenSequenceFeature([], dtype=tf.float32),\n",
    "        \"row_mask\": tf.FixedLenSequenceFeature([], dtype=tf.int64)\n",
    "    }\n",
    "    ctxt_parsed, seq_parsed = tf.parse_single_sequence_example(\n",
    "        serialized=example_proto,\n",
    "        context_features=ctxt_fts,\n",
    "        sequence_features=seq_fts\n",
    "    )\n",
    "    output_shape = [ctxt_parsed['max_t'], ctxt_parsed['max_v']]\n",
    "    output_shape = tf.stack(output_shape)\n",
    "    patient = tf.reshape(seq_parsed['patient'], output_shape)\n",
    "    label = tf.reshape(seq_parsed['label'], output_shape)\n",
    "    demo = tf.reshape(seq_parsed['demo'], output_shape)\n",
    "    row_mask = tf.reshape(seq_parsed['row_mask'], output_shape)\n",
    "    patient_t = tf.reshape(ctxt_parsed['patient_t'], [1,1])\n",
    "    return (patient, label, demo, row_mask, patient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse = raw.map(parse_sequence_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_batch = parse.batch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_batch_it = parse_batch.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 5,  4, -2, -2, -2, -2],\n",
       "         [ 2,  3,  4, -2, -2, -2],\n",
       "         [-2, -2, -2, -2, -2, -2],\n",
       "         [-2, -2, -2, -2, -2, -2],\n",
       "         [-2, -2, -2, -2, -2, -2]],\n",
       " \n",
       "        [[ 5,  6,  4, -2, -2, -2],\n",
       "         [ 0,  3,  6,  5, -2, -2],\n",
       "         [-2, -2, -2, -2, -2, -2],\n",
       "         [-2, -2, -2, -2, -2, -2],\n",
       "         [-2, -2, -2, -2, -2, -2]]], dtype=int64),\n",
       " array([[[ 3,  2, -2, -2, -2, -2],\n",
       "         [ 0,  3,  2, -2, -2, -2],\n",
       "         [-2, -2, -2, -2, -2, -2],\n",
       "         [-2, -2, -2, -2, -2, -2],\n",
       "         [-2, -2, -2, -2, -2, -2]],\n",
       " \n",
       "        [[ 3,  3,  2, -2, -2, -2],\n",
       "         [ 0,  3,  3,  2, -2, -2],\n",
       "         [-2, -2, -2, -2, -2, -2],\n",
       "         [-2, -2, -2, -2, -2, -2],\n",
       "         [-2, -2, -2, -2, -2, -2]]], dtype=int64),\n",
       " array([[[-1.2766646 , -8.258818  ,  1.0295945 , -9.932409  ,\n",
       "           3.4238288 ,  4.7623577 ],\n",
       "         [ 4.781394  , -2.7135177 ,  8.019953  ,  0.30808517,\n",
       "           0.31495225, -3.8640842 ],\n",
       "         [ 0.3880088 , -6.512215  ,  3.4989486 ,  2.7263956 ,\n",
       "          -1.5292437 , -0.5698157 ],\n",
       "         [ 4.377598  , -1.8317424 ,  2.9549975 , -1.0864103 ,\n",
       "           4.6243834 , -0.11334902],\n",
       "         [-7.137146  ,  0.8752901 , -4.1808968 ,  3.2075074 ,\n",
       "           4.62191   , -1.7289466 ]],\n",
       " \n",
       "        [[ 0.16278021,  1.3603187 , -0.5216274 , -4.9485183 ,\n",
       "          -2.2551293 ,  5.401058  ],\n",
       "         [-3.9098558 , -7.839575  ,  9.741207  , -5.906986  ,\n",
       "          -8.789417  , -1.7567434 ],\n",
       "         [ 5.0933104 ,  0.50332713,  2.168022  ,  0.7503062 ,\n",
       "          -1.1831142 , -3.379058  ],\n",
       "         [-1.8852614 , -5.4919615 , -0.5288377 ,  4.906667  ,\n",
       "           4.838065  ,  2.8901198 ],\n",
       "         [ 9.419984  , -0.832394  , -3.65984   , -7.5303655 ,\n",
       "          -9.826516  ,  2.7812753 ]]], dtype=float32),\n",
       " array([[[1, 1, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0]],\n",
       " \n",
       "        [[1, 1, 1, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0]]], dtype=int64),\n",
       " array([[[2]],\n",
       " \n",
       "        [[2]]], dtype=int64))"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(parse_batch_it.get_next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
