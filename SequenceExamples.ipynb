{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {'seqs_file': 4,\n",
    "           'max_v': 6,\n",
    "           'max_t': 5,\n",
    "           'n_codes': 7,\n",
    "           'n_labels': 4,\n",
    "           'seqs_file': 'seqs',\n",
    "           'labels_file': 'labs',\n",
    "           'demo_file': 'demo',\n",
    "           'out_file': 'zipped_TFR',\n",
    "           'n_patients': 4}\n",
    "args = Namespace(**options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(args=args):\n",
    "    \"\"\"Replace later with dataset stuff.\"\"\"\n",
    "    seqs_file = args.seqs_file\n",
    "    if args.labels_file is not None:\n",
    "        labels_file = args.labels_file\n",
    "    seqs = pickle.load(open(seqs_file, 'rb'))\n",
    "    labs = None\n",
    "    if args.labels_file is not None:\n",
    "        labels_file = args.labels_file\n",
    "        labs = pickle.load(open(labels_file, 'rb'))\n",
    "    D_t = None\n",
    "    demo_dim = 0\n",
    "    if args.demo_file is not None:\n",
    "        demo_file = args.demo_file\n",
    "        D_t = pickle.load(open(demo_file, 'rb'))\n",
    "        demo_dim = D_t.shape[-1]\n",
    "        demo = tf.constant(D_t, dtype=tf.float32)\n",
    "        demo = tf.reshape(demo, [args.n_patients, -1])\n",
    "    return seqs, labs, demo, demo_dim\n",
    "\n",
    "\n",
    "def fill_visit(visit, args=args):\n",
    "    \"\"\"Fill all deficit visits with -2.\n",
    "\n",
    "    Ensure that all visits have the same number of ICDs for efficient\n",
    "    tensor logic. If a visit has fewer ICDs, filler ICDs get one-hot\n",
    "    encoded as the zero vector, so that they affect nothing.\n",
    "\n",
    "    visit: a list of integer medical codes\n",
    "\n",
    "    Note: No visit in training or testing should have more than max_v\n",
    "          visits.\n",
    "    \"\"\"\n",
    "    max_v = args.max_v\n",
    "    if visit != [-1]:\n",
    "        new_visit = []\n",
    "        new_visit.extend(visit)\n",
    "        n_icd = len(visit)\n",
    "        deficit = max_v - n_icd\n",
    "        new_visit.extend([-2] * deficit)\n",
    "        return new_visit\n",
    "\n",
    "\n",
    "def fill_patient(patient, mask_batch, args=args):\n",
    "    \"\"\"Ensure that all patients have max_t visits.\n",
    "\n",
    "    Create visits full of -2s, which are one-hot encoded as zero\n",
    "    vectors. This makes all patients commensurate for efficient tensor\n",
    "    logic.\n",
    "\n",
    "    patient: list of list of integer codes\n",
    "    max_t: the number of visits all patients ought to have\n",
    "\n",
    "    Note: No patient in training or test data should have more\n",
    "          than max_t visits.\n",
    "    \"\"\"\n",
    "    max_t = args.max_t\n",
    "    max_v = args.max_v\n",
    "    new_patient = []\n",
    "    new_patient.extend(patient)\n",
    "    new_mask_batch = mask_batch\n",
    "    t = len(new_patient)\n",
    "    deficit = (max_t - t)\n",
    "    new_patient.extend([[-2] * max_v] * deficit)\n",
    "    new_mask_batch.append([[0] * max_v] * deficit)\n",
    "    return new_patient, new_mask_batch, t\n",
    "\n",
    "\n",
    "def tensorize_seqs(seqs, args=args, true_seqs=True):\n",
    "    \"\"\"Convert med2vec to tensorflow data.\n",
    "\n",
    "    seqs: list of list. cf  https://github.com/mp2893/med2vec\n",
    "    true_seqs: bool. Are we tensorizing the true sequences? If false,\n",
    "               we are tonsorizing labels.\n",
    "    returns:\n",
    "        patients: tensor with shape [patients, max_t, max_v, |C|]\n",
    "                  or [patients, max_t, max_v, n_labels] if true_seqs is\n",
    "                  False.\n",
    "        row_masks: numpy array with shape [patients, max_t, max_v]\n",
    "               Later, we will create a [patients, max_t, max_v, |C|]\n",
    "               tensor where the [p, t, i, j] entry is p(c_j|c_i).\n",
    "               Row_masks will drop the rows where c_i is the zero\n",
    "               vector--that is, an NA ICD.\n",
    "\n",
    "               A separate mask, col_mask, will be created from\n",
    "               patients in order to mask, for each t, those j for\n",
    "               which c_j did not appear in visit t, as well as\n",
    "               p(c_i|c_i).\n",
    "\n",
    "               The masks are to be applied in reverse order of creation.\n",
    "               col_mask is applied with tf.multiply and row_masks\n",
    "               with tf.boolean_mask to avoid needless reshaping.\n",
    "        patients_ts: numpy array with shape [patients,] containing the\n",
    "                     number of true visits for each patient.\n",
    "    \"\"\"\n",
    "    patients = []\n",
    "    new_patient = []\n",
    "    row_masks = []\n",
    "    mask_batch = []\n",
    "    patients_ts = []\n",
    "    for visit in seqs + [[-1]]:\n",
    "        if visit != [-1]:\n",
    "            visit = fill_visit(visit, args)\n",
    "            new_patient.append(visit)\n",
    "        else:\n",
    "            new_patient, mask_batch, t = fill_patient(new_patient,\n",
    "                                                      mask_batch,\n",
    "                                                      args)\n",
    "            patients.append(new_patient)\n",
    "            if true_seqs:\n",
    "                patients_ts.append(t)\n",
    "                row_masks.append(mask_batch)\n",
    "                mask_batch = []\n",
    "            new_patient = []\n",
    "    patients = tf.constant(patients)\n",
    "    patients_ts = patients_ts\n",
    "    #patients_ts = tf.expand_dims(patients_ts, -1)\n",
    "    #patients_ts = tf.expand_dims(patients_ts, -1)\n",
    "    row_masks = tf.not_equal(patients, -2)\n",
    "    row_masks = tf.cast(row_masks, tf.int32)\n",
    "    patients = tf.reshape(patients, [args.n_patients, -1])\n",
    "    row_masks = tf.reshape(row_masks, [args.n_patients, -1])\n",
    "    return patients, row_masks, patients_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs, labs, demo, demo_dim = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients, row_masks, patients_ts = tensorize_seqs(seqs, true_seqs=True)\n",
    "labels, _, _ = tensorize_seqs(labs, true_seqs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tf.data.Dataset().from_tensor_slices((patients,\n",
    "                                               row_masks,\n",
    "                                               patients_ts,\n",
    "                                               labels,\n",
    "                                               demo\n",
    "                                              ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_it = output.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#serial = output.map(lambda v,w,x,y,z: (tf.serialize_tensor(v),tf.serialize_tensor(w),tf.serialize_tensor(x),tf.serialize_tensor(y),z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize(func_args_list, args=args):\n",
    "    \"\"\"Turn each row of zipped dataset to example protos for writing to TFR.\"\"\"\n",
    "    ex = tf.train.SequenceExample()\n",
    "    # Non-sequential features of the Example\n",
    "    for key, val in func_args_list:\n",
    "        if key == 'patient_t':\n",
    "            ex.context.feature[key].int64_list.value.append(val)\n",
    "            \n",
    "        elif key == 'demo':\n",
    "            for scalar in val:\n",
    "                (ex.feature_lists.feature_list[key].feature\n",
    "                                                   .add()\n",
    "                                                   .float_list\n",
    "                                                   .value\n",
    "                                                   .append(scalar))\n",
    "        else:\n",
    "            for scalar in val:\n",
    "                (ex.feature_lists.feature_list[key].feature\n",
    "                                                   .add()\n",
    "                                                   .int64_list\n",
    "                                                   .value\n",
    "                                                   .append(scalar))\n",
    "    ex.context.feature[\"max_t\"].int64_list.value.append(args.max_t)\n",
    "    ex.context.feature[\"max_v\"].int64_list.value.append(args.max_v)\n",
    "    return ex.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_serialize(row_dict):\n",
    "    \"\"\"Map serialize_with_labels to tf.data.Dataset.\"\"\"\n",
    "    func_args = [(key, val) for key, val in row_dict.items()]\n",
    "    tf_string = tf.py_func(serialize,\n",
    "                           func_args,\n",
    "                           tf.string)\n",
    "    return tf.reshape(tf_string, ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Tensors in list passed to 'input' of 'PyFunc' Op have types [<NOT CONVERTIBLE TO TENSOR>, <NOT CONVERTIBLE TO TENSOR>, <NOT CONVERTIBLE TO TENSOR>, <NOT CONVERTIBLE TO TENSOR>, <NOT CONVERTIBLE TO TENSOR>] that are invalid.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    454\u001b[0m                 \u001b[0mpreferred_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 455\u001b[1;33m                 as_ref=input_arg.is_ref)\n\u001b[0m\u001b[0;32m    456\u001b[0m             if input_arg.number_attr and len(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36minternal_convert_n_to_tensor\u001b[1;34m(values, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[0;32m   1158\u001b[0m             \u001b[0mpreferred_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1159\u001b[1;33m             ctx=ctx))\n\u001b[0m\u001b[0;32m   1160\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[0;32m   1093\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1094\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1095\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m_autopacking_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    960\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0m_autopacking_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m\"packed\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    962\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m_autopacking_helper\u001b[1;34m(list_or_tuple, dtype, name)\u001b[0m\n\u001b[0;32m    922\u001b[0m           elems_as_tensors.append(\n\u001b[1;32m--> 923\u001b[1;33m               constant_op.constant(elem, dtype=dtype, name=str(i)))\n\u001b[0m\u001b[0;32m    924\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melems_as_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[0;32m    195\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[1;32m--> 196\u001b[1;33m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[0;32m    197\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[1;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    435\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m       \u001b[0m_AssertCompatible\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m       \u001b[0mnparray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp_dt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36m_AssertCompatible\u001b[1;34m(values, dtype)\u001b[0m\n\u001b[0;32m    346\u001b[0m       raise TypeError(\"Expected %s, got %s of type '%s' instead.\" %\n\u001b[1;32m--> 347\u001b[1;33m                       (dtype.name, repr(mismatch), type(mismatch).__name__))\n\u001b[0m\u001b[0;32m    348\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected int32, got 'patients' of type 'str' instead.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-98a6c7c6feaf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mserialized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf_serialize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[0;32m    984\u001b[0m     \"\"\"\n\u001b[0;32m    985\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mParallelMapDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, map_func)\u001b[0m\n\u001b[0;32m   2196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2197\u001b[0m     wrapped_func = StructuredFunctionWrapper(\n\u001b[1;32m-> 2198\u001b[1;33m         map_func, \"Dataset.map()\", input_dataset)\n\u001b[0m\u001b[0;32m   2199\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2200\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_shapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_shapes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, add_to_graph, experimental_nested_dataset_support)\u001b[0m\n\u001b[0;32m   1452\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_data_structured_function_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1454\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1455\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1456\u001b[0m       \u001b[1;31m# Use the private method that will execute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\u001b[0m in \u001b[0;36madd_to_graph\u001b[1;34m(self, g)\u001b[0m\n\u001b[0;32m    479\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    480\u001b[0m     \u001b[1;34m\"\"\"Adds this function into the graph g.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 481\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_definition_if_needed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    482\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    483\u001b[0m     \u001b[1;31m# Adds this function into 'g'.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\u001b[0m in \u001b[0;36m_create_definition_if_needed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[1;34m\"\"\"Creates the function definition if it's not created yet.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 337\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_definition_if_needed_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_create_definition_if_needed_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\u001b[0m in \u001b[0;36m_create_definition_if_needed_impl\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    344\u001b[0m     temp_graph = func_graph_from_py_func(\n\u001b[0;32m    345\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_arg_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_arg_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m         self._capture_by_value, self._caller_device)\n\u001b[0m\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extra_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextra_inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(func, arg_names, arg_types, name, capture_by_value, device, colocation_stack, container, collections_ref)\u001b[0m\n\u001b[0;32m    861\u001b[0m     \u001b[1;31m# Call func and gather the output tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mvs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 863\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    864\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m     \u001b[1;31m# There is no way of distinguishing between a function not returning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mtf_data_structured_function_wrapper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   1390\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1392\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1393\u001b[0m       \u001b[1;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m       \u001b[1;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-ad976cce7114>\u001b[0m in \u001b[0;36mtf_serialize\u001b[1;34m(row_dict)\u001b[0m\n\u001b[0;32m      4\u001b[0m     tf_string = tf.py_func(serialize,\n\u001b[0;32m      5\u001b[0m                            \u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                            tf.string)\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\u001b[0m in \u001b[0;36mpy_func\u001b[1;34m(func, inp, Tout, stateful, name)\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m   return _internal_py_func(\n\u001b[1;32m--> 456\u001b[1;33m       func=func, inp=inp, Tout=Tout, stateful=stateful, eager=False, name=name)\n\u001b[0m\u001b[0;32m    457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\u001b[0m in \u001b[0;36m_internal_py_func\u001b[1;34m(func, inp, Tout, stateful, eager, is_grad_func, name)\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m       result = gen_script_ops.py_func(\n\u001b[1;32m--> 281\u001b[1;33m           input=inp, token=token, Tout=Tout, name=name)\n\u001b[0m\u001b[0;32m    282\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m       result = gen_script_ops.py_func_stateless(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_script_ops.py\u001b[0m in \u001b[0;36mpy_func\u001b[1;34m(input, token, Tout, name)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[0mTout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Tout\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_t\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mTout\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m--> 127\u001b[1;33m         \"PyFunc\", input=input, token=token, Tout=Tout, name=name)\n\u001b[0m\u001b[0;32m    128\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    483\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s that don't all match.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 485\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s that are invalid.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m           \u001b[0mtypes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Tensors in list passed to 'input' of 'PyFunc' Op have types [<NOT CONVERTIBLE TO TENSOR>, <NOT CONVERTIBLE TO TENSOR>, <NOT CONVERTIBLE TO TENSOR>, <NOT CONVERTIBLE TO TENSOR>, <NOT CONVERTIBLE TO TENSOR>] that are invalid."
     ]
    }
   ],
   "source": [
    "serialized = output.map(tf_serialize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialized_it = serialized.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = sess.run(serialized_it.get_next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.contrib.data.TFRecordWriter(args.out_file)\n",
    "writeop = writer.write(serialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(writeop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = tf.data.TFRecordDataset([args.out_file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_it = raw.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = sess.run(raw_it.get_next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sequence_examples(example_proto, args=args):\n",
    "    ctxt_fts = {\n",
    "        \"patient_t\": tf.FixedLenFeature([], dtype=tf.int64),\n",
    "        \"max_t\": tf.FixedLenFeature([], dtype=tf.int64),\n",
    "        \"max_v\": tf.FixedLenFeature([], dtype=tf.int64),\n",
    "    }\n",
    "    seq_fts = {\n",
    "        \"patient\": tf.FixedLenSequenceFeature([], dtype=tf.int64),\n",
    "        \"label\": tf.FixedLenSequenceFeature([], dtype=tf.int64),\n",
    "        \"demo\": tf.FixedLenSequenceFeature([], dtype=tf.float32),\n",
    "        \"row_mask\": tf.FixedLenSequenceFeature([], dtype=tf.int64)\n",
    "    }\n",
    "    ctxt_parsed, seq_parsed = tf.parse_single_sequence_example(\n",
    "        serialized=example_proto,\n",
    "        context_features=ctxt_fts,\n",
    "        sequence_features=seq_fts\n",
    "    )\n",
    "    output_shape = [ctxt_parsed['max_t'], ctxt_parsed['max_v']]\n",
    "    output_shape = tf.stack(output_shape)\n",
    "    patient = tf.reshape(seq_parsed['patient'], output_shape)\n",
    "    label = tf.reshape(seq_parsed['label'], output_shape)\n",
    "    demo = tf.reshape(seq_parsed['demo'], output_shape)\n",
    "    row_mask = tf.reshape(seq_parsed['row_mask'], output_shape)\n",
    "    patient_t = tf.reshape(ctxt_parsed['patient_t'], [1,1])\n",
    "    return (patient, label, demo, row_mask, patient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse = raw.map(parse_sequence_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_batch = parse.batch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_batch_it = parse_batch.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 5,  4, -2, -2, -2, -2],\n",
       "         [ 2,  3,  4, -2, -2, -2],\n",
       "         [-2, -2, -2, -2, -2, -2],\n",
       "         [-2, -2, -2, -2, -2, -2],\n",
       "         [-2, -2, -2, -2, -2, -2]],\n",
       " \n",
       "        [[ 5,  6,  4, -2, -2, -2],\n",
       "         [ 0,  3,  6,  5, -2, -2],\n",
       "         [-2, -2, -2, -2, -2, -2],\n",
       "         [-2, -2, -2, -2, -2, -2],\n",
       "         [-2, -2, -2, -2, -2, -2]]], dtype=int64),\n",
       " array([[[ 3,  2, -2, -2, -2, -2],\n",
       "         [ 0,  3,  2, -2, -2, -2],\n",
       "         [-2, -2, -2, -2, -2, -2],\n",
       "         [-2, -2, -2, -2, -2, -2],\n",
       "         [-2, -2, -2, -2, -2, -2]],\n",
       " \n",
       "        [[ 3,  3,  2, -2, -2, -2],\n",
       "         [ 0,  3,  3,  2, -2, -2],\n",
       "         [-2, -2, -2, -2, -2, -2],\n",
       "         [-2, -2, -2, -2, -2, -2],\n",
       "         [-2, -2, -2, -2, -2, -2]]], dtype=int64),\n",
       " array([[[-1.2766646 , -8.258818  ,  1.0295945 , -9.932409  ,\n",
       "           3.4238288 ,  4.7623577 ],\n",
       "         [ 4.781394  , -2.7135177 ,  8.019953  ,  0.30808517,\n",
       "           0.31495225, -3.8640842 ],\n",
       "         [ 0.3880088 , -6.512215  ,  3.4989486 ,  2.7263956 ,\n",
       "          -1.5292437 , -0.5698157 ],\n",
       "         [ 4.377598  , -1.8317424 ,  2.9549975 , -1.0864103 ,\n",
       "           4.6243834 , -0.11334902],\n",
       "         [-7.137146  ,  0.8752901 , -4.1808968 ,  3.2075074 ,\n",
       "           4.62191   , -1.7289466 ]],\n",
       " \n",
       "        [[ 0.16278021,  1.3603187 , -0.5216274 , -4.9485183 ,\n",
       "          -2.2551293 ,  5.401058  ],\n",
       "         [-3.9098558 , -7.839575  ,  9.741207  , -5.906986  ,\n",
       "          -8.789417  , -1.7567434 ],\n",
       "         [ 5.0933104 ,  0.50332713,  2.168022  ,  0.7503062 ,\n",
       "          -1.1831142 , -3.379058  ],\n",
       "         [-1.8852614 , -5.4919615 , -0.5288377 ,  4.906667  ,\n",
       "           4.838065  ,  2.8901198 ],\n",
       "         [ 9.419984  , -0.832394  , -3.65984   , -7.5303655 ,\n",
       "          -9.826516  ,  2.7812753 ]]], dtype=float32),\n",
       " array([[[1, 1, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0]],\n",
       " \n",
       "        [[1, 1, 1, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0]]], dtype=int64),\n",
       " array([[[2]],\n",
       " \n",
       "        [[2]]], dtype=int64))"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(parse_batch_it.get_next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
