{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "import collections\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = [[5, 8], [-1], [5, 6, 7], [0, 6, 9, 5], [-1], [9, 6], [5, 8, 7], [7, 4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairs(alist):\n",
    "    return zip(alist, alist[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code-level cost:\n",
    "\n",
    "$\\frac{1}{T}\\sum\\limits_{t=1}^T\\sum\\limits_{i:c_i\\in V_t}\\sum\\limits_{j:c_j\\in V_t, i\\neq j}\\log{\\text{p}(c_j|c_i)}$\n",
    "\n",
    "$\\text{p}(c_j|c_i) = \\frac{\\exp{(e_j\\cdot e_i)}}{\\sum\\limits_{k=1}^{|C|}\\exp{(e_k\\cdot e_i)}}$\n",
    "\n",
    "Where $e_i$ is the $i^{th}$ column of $W_c$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumptions:\n",
    "- Should work with process_mimic, so seqs and types will have the form of the originals\n",
    "- However, we will assume a visit has a maximum number (maxV = unspecified) of ICDs, some of which may be NA.\n",
    "- A batch is a batch of patients, who have T_k visits, each of which has maxV ICDs, some of which may be NA (blank).\n",
    "- That is, after processing, a batch will have shape [batch, maxT, maxV, |C|], where each [maxV, |C|] vector is a one_hot encoding of an ICD present in the visit (all zeros if one of the maxT ICDs is blank)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 8], [-1], [5, 6, 7], [0, 6, 9, 5], [-1], [9, 6], [5, 8, 7], [7, 4]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs = [[5, 8], [-1], [5, 6, 7], [0, 6, 9, 5], [-1], [9, 6], [5, 8, 7], [7, 4]]\n",
    "seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {'max_v': 5, 'max_t': 3, 'n_codes': 10}\n",
    "\n",
    "def fill_visit(visit, **options):\n",
    "    \"\"\"Fill all deficit visits with -2.\n",
    "    \n",
    "    Ensure that all visits have the same number of ICDs\n",
    "    for efficient tensor logic. If a visit has fewer ICDs,\n",
    "    filler ICDs get one-hot encoded as the zero vector,\n",
    "    so that they affect nothing.\n",
    "    \n",
    "    visit: a list of integer medical codes\n",
    "    \n",
    "    Note: No visit in training or testing should have more\n",
    "    than max_v visits.\n",
    "    \"\"\"\n",
    "    max_v = options['max_v']\n",
    "    if visit != [-1]:\n",
    "        new_visit = []\n",
    "        new_visit.extend(visit)\n",
    "        n_icd = len(visit)\n",
    "        deficit = max_v - n_icd\n",
    "        new_visit.extend([-2] * deficit)\n",
    "        return new_visit\n",
    "    \n",
    "\n",
    "def fill_patient(patient, mask_batch, **options):\n",
    "    \"\"\"Ensure that all patients have max_t visits.\n",
    "    \n",
    "    Create visits full of -2s, which are one-hot\n",
    "    encoded as zero vectors. This makes all patients\n",
    "    commensurate for efficient tensor logic.\n",
    "    \n",
    "    patient: list of list of integer codes\n",
    "    max_t: the number of visits all patients ought to have\n",
    "    \n",
    "    Note: No patient in training or test data should have more \n",
    "    than max_t visits.\n",
    "    \"\"\"\n",
    "    max_t = options['max_t']\n",
    "    max_v = options['max_v']\n",
    "    new_patient = []\n",
    "    new_patient.extend(patient)\n",
    "    new_mask_batch = mask_batch\n",
    "    t = len(new_patient)\n",
    "    deficit = (max_t - t)\n",
    "    new_patient.extend([[-2] * max_v] * deficit)\n",
    "    new_mask_batch.append([[0] * max_v] * deficit)\n",
    "    return new_patient, new_mask_batch, t\n",
    "\n",
    "def tensorize_seqs(seqs, **options):\n",
    "    \"\"\"Convert med2vec to tensorflow data.\n",
    "    \n",
    "    seqs: list of list. cf  https://github.com/mp2893/med2vec\n",
    "    \n",
    "    returns:\n",
    "        patients: tensor with shape [patients, max_t, max_v, |C|]\n",
    "        row_masks: numpy array with shape [patients, max_t, max_v]\n",
    "               Later, we will create a [patients, max_t, max_v, |C|]\n",
    "               tensor where the [p, t, i, j] entry is p(c_j|c_i).\n",
    "               Row_masks will drop the rows where c_i is the zero\n",
    "               vector--that is, an NA ICD.\n",
    "               \n",
    "               A separate mask, col_mask, will be created from\n",
    "               patients in order to mask, for each t, those j for\n",
    "               which c_j did not appear in visit t, as well as p(c_i|c_i).\n",
    "               \n",
    "               The masks are to be applied in reverse order of creation.\n",
    "               col_mask is applied with tf.multiply and row_masks\n",
    "               with tf.boolean_mask to avoid needless reshaping.\n",
    "    \"\"\"\n",
    "    max_v = options['max_v']\n",
    "    n_codes = options['n_codes']\n",
    "    patients = []\n",
    "    new_patient = []\n",
    "    row_masks = []\n",
    "    mask_batch = []\n",
    "    patients_ts = []\n",
    "    for visit in seqs + [[-1]]:\n",
    "        if visit != [-1]:\n",
    "            visit = fill_visit(visit, **options)\n",
    "            new_patient.append(visit)\n",
    "        else:\n",
    "            new_patient, mask_batch, t = fill_patient(new_patient,\n",
    "                                                   mask_batch,\n",
    "                                                   **options)\n",
    "            patients.append(new_patient)\n",
    "            patients_ts.append(t)\n",
    "            row_masks.append(mask_batch)\n",
    "            new_patient = []\n",
    "            mask_batch = []\n",
    "    patients = np.array(patients)\n",
    "    row_masks = (patients != -2)\n",
    "    patients = tf.one_hot(patients, depth=n_codes)\n",
    "    return patients, row_masks, np.array(patients_ts, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the cost of a single visit. Need to work on broadcasting for multiple visits, so batches can be in terms of patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  3.,  5.],\n",
       "       [ 7., 11., 13., 17.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = np.array([[1,2,3,5],[7,11,13,17]], dtype=np.float32)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_i = np.array([1,0,0,0], dtype=np.float32)\n",
    "c_j = np.array([0,0,1,0], dtype=np.float32)\n",
    "c_k = np.array([0,0,0,0], dtype=np.float32)\n",
    "x_t = c_i + c_j + c_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_t = np.stack([c_i, c_j, c_k])\n",
    "V_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.],\n",
       "        [ 7.]],\n",
       "\n",
       "       [[ 3.],\n",
       "        [13.]],\n",
       "\n",
       "       [[ 0.],\n",
       "        [ 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_ij = tf.matmul(W, V_t, transpose_b=True)\n",
    "w_ij = tf.reshape(tf.transpose(w_ij),[3,2,1])\n",
    "w_ij.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [7.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_i = tf.matmul(W, tf.reshape(c_i, [1,4]), transpose_b=True).eval()\n",
    "w_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.,  2.,  3.,  5.],\n",
       "        [ 7., 11., 13., 17.]],\n",
       "\n",
       "       [[ 1.,  2.,  3.,  5.],\n",
       "        [ 7., 11., 13., 17.]],\n",
       "\n",
       "       [[ 1.,  2.,  3.,  5.],\n",
       "        [ 7., 11., 13., 17.]]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_tiled = tf.tile(tf.expand_dims(W, 0), [3, 1, 1])\n",
    "W_tiled.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  1.,   2.,   3.,   5.],\n",
       "        [ 49.,  77.,  91., 119.]],\n",
       "\n",
       "       [[  3.,   6.,   9.,  15.],\n",
       "        [ 91., 143., 169., 221.]],\n",
       "\n",
       "       [[  0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.]]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_sum = tf.multiply(W_tiled, w_ij)\n",
    "pre_sum.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 50.,  79.,  94., 124.],\n",
       "       [ 94., 149., 178., 236.],\n",
       "       [  0.,   0.,   0.,   0.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_soft = tf.reduce_sum(pre_sum, axis=-2)\n",
    "pre_soft.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.2812905e-33, 2.8625186e-20, 9.3576229e-14, 1.0000000e+00],\n",
       "       [0.0000000e+00, 1.6458115e-38, 6.4702347e-26, 1.0000000e+00],\n",
       "       [2.5000000e-01, 2.5000000e-01, 2.5000000e-01, 2.5000000e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(pre_soft, axis=-1).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do: deal with mask, log, sum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The above section all happens at the single-visit level. Need to expand to the level of multiple patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  3.,  5.,  7.],\n",
       "       [11., 13., 17., 23., 29.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = np.array([[1,2,3,5, 7],[11,13,17,23, 29]], dtype=np.float32)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = [[0,1],[1],[-1],[3,1],[1,2,3],[3]] # 2 patients, 2 and 3 visits respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {'max_t': 4, 'max_v': 3, 'n_codes': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients, row_masks, patients_ts = tensorize_seqs(seqs, **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ True,  True, False],\n",
       "        [ True, False, False],\n",
       "        [False, False, False],\n",
       "        [False, False, False]],\n",
       "\n",
       "       [[ True,  True, False],\n",
       "        [ True,  True,  True],\n",
       "        [ True, False, False],\n",
       "        [False, False, False]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 1., 0.],\n",
       "         [0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 1., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 1., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 1.,  2.,  3.,  5.,  7.],\n",
       "         [11., 13., 17., 23., 29.]],\n",
       "\n",
       "        [[ 1.,  2.,  3.,  5.,  7.],\n",
       "         [11., 13., 17., 23., 29.]],\n",
       "\n",
       "        [[ 1.,  2.,  3.,  5.,  7.],\n",
       "         [11., 13., 17., 23., 29.]],\n",
       "\n",
       "        [[ 1.,  2.,  3.,  5.,  7.],\n",
       "         [11., 13., 17., 23., 29.]]],\n",
       "\n",
       "\n",
       "       [[[ 1.,  2.,  3.,  5.,  7.],\n",
       "         [11., 13., 17., 23., 29.]],\n",
       "\n",
       "        [[ 1.,  2.,  3.,  5.,  7.],\n",
       "         [11., 13., 17., 23., 29.]],\n",
       "\n",
       "        [[ 1.,  2.,  3.,  5.,  7.],\n",
       "         [11., 13., 17., 23., 29.]],\n",
       "\n",
       "        [[ 1.,  2.,  3.,  5.,  7.],\n",
       "         [11., 13., 17., 23., 29.]]]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_tiled = tf.expand_dims(W, 0)\n",
    "W_tiled = tf.expand_dims(W_tiled, 0)\n",
    "W_tiled = tf.tile(W_tiled, [2, 4, 1, 1])\n",
    "W_tiled.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4, 2, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_tiled.eval().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 1.,  2.,  0.],\n",
       "         [11., 13.,  0.]],\n",
       "\n",
       "        [[ 2.,  0.,  0.],\n",
       "         [13.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]]],\n",
       "\n",
       "\n",
       "       [[[ 5.,  2.,  0.],\n",
       "         [23., 13.,  0.]],\n",
       "\n",
       "        [[ 2.,  3.,  5.],\n",
       "         [13., 17., 23.]],\n",
       "\n",
       "        [[ 5.,  0.,  0.],\n",
       "         [23.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]]]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_ij = tf.matmul(W_tiled, patients, transpose_b=True)\n",
    "w_ij.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4, 2, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_ij.eval().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 1., 11.],\n",
       "         [ 2., 13.],\n",
       "         [ 0.,  0.]],\n",
       "\n",
       "        [[ 2., 13.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.]]],\n",
       "\n",
       "\n",
       "       [[[ 5., 23.],\n",
       "         [ 2., 13.],\n",
       "         [ 0.,  0.]],\n",
       "\n",
       "        [[ 2., 13.],\n",
       "         [ 3., 17.],\n",
       "         [ 5., 23.]],\n",
       "\n",
       "        [[ 5., 23.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.]]]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_ij = tf.transpose(w_ij, [0,1,3,2])\n",
    "w_ij.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[ 1.],\n",
       "          [11.]],\n",
       "\n",
       "         [[ 2.],\n",
       "          [13.]],\n",
       "\n",
       "         [[ 0.],\n",
       "          [ 0.]]],\n",
       "\n",
       "\n",
       "        [[[ 2.],\n",
       "          [13.]],\n",
       "\n",
       "         [[ 0.],\n",
       "          [ 0.]],\n",
       "\n",
       "         [[ 0.],\n",
       "          [ 0.]]],\n",
       "\n",
       "\n",
       "        [[[ 0.],\n",
       "          [ 0.]],\n",
       "\n",
       "         [[ 0.],\n",
       "          [ 0.]],\n",
       "\n",
       "         [[ 0.],\n",
       "          [ 0.]]],\n",
       "\n",
       "\n",
       "        [[[ 0.],\n",
       "          [ 0.]],\n",
       "\n",
       "         [[ 0.],\n",
       "          [ 0.]],\n",
       "\n",
       "         [[ 0.],\n",
       "          [ 0.]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[ 5.],\n",
       "          [23.]],\n",
       "\n",
       "         [[ 2.],\n",
       "          [13.]],\n",
       "\n",
       "         [[ 0.],\n",
       "          [ 0.]]],\n",
       "\n",
       "\n",
       "        [[[ 2.],\n",
       "          [13.]],\n",
       "\n",
       "         [[ 3.],\n",
       "          [17.]],\n",
       "\n",
       "         [[ 5.],\n",
       "          [23.]]],\n",
       "\n",
       "\n",
       "        [[[ 5.],\n",
       "          [23.]],\n",
       "\n",
       "         [[ 0.],\n",
       "          [ 0.]],\n",
       "\n",
       "         [[ 0.],\n",
       "          [ 0.]]],\n",
       "\n",
       "\n",
       "        [[[ 0.],\n",
       "          [ 0.]],\n",
       "\n",
       "         [[ 0.],\n",
       "          [ 0.]],\n",
       "\n",
       "         [[ 0.],\n",
       "          [ 0.]]]]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_ij = tf.reshape(w_ij,[2,4,3,2,1])\n",
    "w_ij.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  3.,  5.,  7.],\n",
       "       [11., 13., 17., 23., 29.]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[  1.,   2.,   3.,   5.,   7.],\n",
       "          [121., 143., 187., 253., 319.]],\n",
       "\n",
       "         [[  2.,   4.,   6.,  10.,  14.],\n",
       "          [143., 169., 221., 299., 377.]],\n",
       "\n",
       "         [[  0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.]]],\n",
       "\n",
       "\n",
       "        [[[  2.,   4.,   6.,  10.,  14.],\n",
       "          [143., 169., 221., 299., 377.]],\n",
       "\n",
       "         [[  0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.]],\n",
       "\n",
       "         [[  0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.]]],\n",
       "\n",
       "\n",
       "        [[[  0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.]],\n",
       "\n",
       "         [[  0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.]],\n",
       "\n",
       "         [[  0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.]]],\n",
       "\n",
       "\n",
       "        [[[  0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.]],\n",
       "\n",
       "         [[  0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.]],\n",
       "\n",
       "         [[  0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[  5.,  10.,  15.,  25.,  35.],\n",
       "          [253., 299., 391., 529., 667.]],\n",
       "\n",
       "         [[  2.,   4.,   6.,  10.,  14.],\n",
       "          [143., 169., 221., 299., 377.]],\n",
       "\n",
       "         [[  0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.]]],\n",
       "\n",
       "\n",
       "        [[[  2.,   4.,   6.,  10.,  14.],\n",
       "          [143., 169., 221., 299., 377.]],\n",
       "\n",
       "         [[  3.,   6.,   9.,  15.,  21.],\n",
       "          [187., 221., 289., 391., 493.]],\n",
       "\n",
       "         [[  5.,  10.,  15.,  25.,  35.],\n",
       "          [253., 299., 391., 529., 667.]]],\n",
       "\n",
       "\n",
       "        [[[  5.,  10.,  15.,  25.,  35.],\n",
       "          [253., 299., 391., 529., 667.]],\n",
       "\n",
       "         [[  0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.]],\n",
       "\n",
       "         [[  0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.]]],\n",
       "\n",
       "\n",
       "        [[[  0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.]],\n",
       "\n",
       "         [[  0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.]],\n",
       "\n",
       "         [[  0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.]]]]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_sum = tf.multiply(W, w_ij)\n",
    "pre_sum.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[122., 145., 190., 258., 326.],\n",
       "         [145., 173., 227., 309., 391.],\n",
       "         [  0.,   0.,   0.,   0.,   0.]],\n",
       "\n",
       "        [[145., 173., 227., 309., 391.],\n",
       "         [  0.,   0.,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0.,   0.,   0.]],\n",
       "\n",
       "        [[  0.,   0.,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0.,   0.,   0.]],\n",
       "\n",
       "        [[  0.,   0.,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0.,   0.,   0.]]],\n",
       "\n",
       "\n",
       "       [[[258., 309., 406., 554., 702.],\n",
       "         [145., 173., 227., 309., 391.],\n",
       "         [  0.,   0.,   0.,   0.,   0.]],\n",
       "\n",
       "        [[145., 173., 227., 309., 391.],\n",
       "         [190., 227., 298., 406., 514.],\n",
       "         [258., 309., 406., 554., 702.]],\n",
       "\n",
       "        [[258., 309., 406., 554., 702.],\n",
       "         [  0.,   0.,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0.,   0.,   0.]],\n",
       "\n",
       "        [[  0.,   0.,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0.,   0.,   0.]]]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = tf.reduce_sum(pre_sum, -2)\n",
    "logits.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.9374821e-30,\n",
       "          1.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.4426007e-36,\n",
       "          1.0000000e+00],\n",
       "         [2.0000000e-01, 2.0000000e-01, 2.0000000e-01, 2.0000000e-01,\n",
       "          2.0000000e-01]],\n",
       "\n",
       "        [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.4426007e-36,\n",
       "          1.0000000e+00],\n",
       "         [2.0000000e-01, 2.0000000e-01, 2.0000000e-01, 2.0000000e-01,\n",
       "          2.0000000e-01],\n",
       "         [2.0000000e-01, 2.0000000e-01, 2.0000000e-01, 2.0000000e-01,\n",
       "          2.0000000e-01]],\n",
       "\n",
       "        [[2.0000000e-01, 2.0000000e-01, 2.0000000e-01, 2.0000000e-01,\n",
       "          2.0000000e-01],\n",
       "         [2.0000000e-01, 2.0000000e-01, 2.0000000e-01, 2.0000000e-01,\n",
       "          2.0000000e-01],\n",
       "         [2.0000000e-01, 2.0000000e-01, 2.0000000e-01, 2.0000000e-01,\n",
       "          2.0000000e-01]],\n",
       "\n",
       "        [[2.0000000e-01, 2.0000000e-01, 2.0000000e-01, 2.0000000e-01,\n",
       "          2.0000000e-01],\n",
       "         [2.0000000e-01, 2.0000000e-01, 2.0000000e-01, 2.0000000e-01,\n",
       "          2.0000000e-01],\n",
       "         [2.0000000e-01, 2.0000000e-01, 2.0000000e-01, 2.0000000e-01,\n",
       "          2.0000000e-01]]],\n",
       "\n",
       "\n",
       "       [[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          1.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.4426007e-36,\n",
       "          1.0000000e+00],\n",
       "         [2.0000000e-01, 2.0000000e-01, 2.0000000e-01, 2.0000000e-01,\n",
       "          2.0000000e-01]],\n",
       "\n",
       "        [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.4426007e-36,\n",
       "          1.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          1.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          1.0000000e+00]],\n",
       "\n",
       "        [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          1.0000000e+00],\n",
       "         [2.0000000e-01, 2.0000000e-01, 2.0000000e-01, 2.0000000e-01,\n",
       "          2.0000000e-01],\n",
       "         [2.0000000e-01, 2.0000000e-01, 2.0000000e-01, 2.0000000e-01,\n",
       "          2.0000000e-01]],\n",
       "\n",
       "        [[2.0000000e-01, 2.0000000e-01, 2.0000000e-01, 2.0000000e-01,\n",
       "          2.0000000e-01],\n",
       "         [2.0000000e-01, 2.0000000e-01, 2.0000000e-01, 2.0000000e-01,\n",
       "          2.0000000e-01],\n",
       "         [2.0000000e-01, 2.0000000e-01, 2.0000000e-01, 2.0000000e-01,\n",
       "          2.0000000e-01]]]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_j_i = tf.nn.softmax(logits, -1)\n",
    "p_j_i.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_eps = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-1.3815511e+01, -1.3815511e+01, -1.3815511e+01,\n",
       "          -1.3815511e+01,  9.5367386e-07],\n",
       "         [-1.3815511e+01, -1.3815511e+01, -1.3815511e+01,\n",
       "          -1.3815511e+01,  9.5367386e-07],\n",
       "         [-1.6094329e+00, -1.6094329e+00, -1.6094329e+00,\n",
       "          -1.6094329e+00, -1.6094329e+00]],\n",
       "\n",
       "        [[-1.3815511e+01, -1.3815511e+01, -1.3815511e+01,\n",
       "          -1.3815511e+01,  9.5367386e-07],\n",
       "         [-1.6094329e+00, -1.6094329e+00, -1.6094329e+00,\n",
       "          -1.6094329e+00, -1.6094329e+00],\n",
       "         [-1.6094329e+00, -1.6094329e+00, -1.6094329e+00,\n",
       "          -1.6094329e+00, -1.6094329e+00]],\n",
       "\n",
       "        [[-1.6094329e+00, -1.6094329e+00, -1.6094329e+00,\n",
       "          -1.6094329e+00, -1.6094329e+00],\n",
       "         [-1.6094329e+00, -1.6094329e+00, -1.6094329e+00,\n",
       "          -1.6094329e+00, -1.6094329e+00],\n",
       "         [-1.6094329e+00, -1.6094329e+00, -1.6094329e+00,\n",
       "          -1.6094329e+00, -1.6094329e+00]],\n",
       "\n",
       "        [[-1.6094329e+00, -1.6094329e+00, -1.6094329e+00,\n",
       "          -1.6094329e+00, -1.6094329e+00],\n",
       "         [-1.6094329e+00, -1.6094329e+00, -1.6094329e+00,\n",
       "          -1.6094329e+00, -1.6094329e+00],\n",
       "         [-1.6094329e+00, -1.6094329e+00, -1.6094329e+00,\n",
       "          -1.6094329e+00, -1.6094329e+00]]],\n",
       "\n",
       "\n",
       "       [[[-1.3815511e+01, -1.3815511e+01, -1.3815511e+01,\n",
       "          -1.3815511e+01,  9.5367386e-07],\n",
       "         [-1.3815511e+01, -1.3815511e+01, -1.3815511e+01,\n",
       "          -1.3815511e+01,  9.5367386e-07],\n",
       "         [-1.6094329e+00, -1.6094329e+00, -1.6094329e+00,\n",
       "          -1.6094329e+00, -1.6094329e+00]],\n",
       "\n",
       "        [[-1.3815511e+01, -1.3815511e+01, -1.3815511e+01,\n",
       "          -1.3815511e+01,  9.5367386e-07],\n",
       "         [-1.3815511e+01, -1.3815511e+01, -1.3815511e+01,\n",
       "          -1.3815511e+01,  9.5367386e-07],\n",
       "         [-1.3815511e+01, -1.3815511e+01, -1.3815511e+01,\n",
       "          -1.3815511e+01,  9.5367386e-07]],\n",
       "\n",
       "        [[-1.3815511e+01, -1.3815511e+01, -1.3815511e+01,\n",
       "          -1.3815511e+01,  9.5367386e-07],\n",
       "         [-1.6094329e+00, -1.6094329e+00, -1.6094329e+00,\n",
       "          -1.6094329e+00, -1.6094329e+00],\n",
       "         [-1.6094329e+00, -1.6094329e+00, -1.6094329e+00,\n",
       "          -1.6094329e+00, -1.6094329e+00]],\n",
       "\n",
       "        [[-1.6094329e+00, -1.6094329e+00, -1.6094329e+00,\n",
       "          -1.6094329e+00, -1.6094329e+00],\n",
       "         [-1.6094329e+00, -1.6094329e+00, -1.6094329e+00,\n",
       "          -1.6094329e+00, -1.6094329e+00],\n",
       "         [-1.6094329e+00, -1.6094329e+00, -1.6094329e+00,\n",
       "          -1.6094329e+00, -1.6094329e+00]]]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_p_j_i = tf.log(p_j_i + log_eps)\n",
    "log_p_j_i.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4, 3, 5)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_p_j_i.eval().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4, 3, 5)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients.eval().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_masks(patients, **options):\n",
    "    \"\"\"Create a mask to cover non-present ICDs.\n",
    "    \n",
    "    For each V_t, for each c_i in V_t,\n",
    "    zero out those p(c_j|c_i) for which c_j is not\n",
    "    in V_t or for which i==j.\n",
    "    \n",
    "    See doc string for tensorize_seqs.\n",
    "    \n",
    "    patients: [patients,max_t,max_v,|C|] tensor\n",
    "    \n",
    "    returns: a binary tensor with shape patients.shape\n",
    "    \"\"\"\n",
    "    max_v = options['max_v']\n",
    "    x_t = tf.reduce_sum(patients, axis=-2)\n",
    "    x_t = tf.expand_dims(x_t, -2)\n",
    "    x_t = tf.tile(x_t, [1,1,max_v,1])\n",
    "    col_masks = x_t - patients\n",
    "    return col_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0., 1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0.],\n",
       "         [1., 1., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0.],\n",
       "         [0., 1., 0., 1., 0.]],\n",
       "\n",
       "        [[0., 0., 1., 1., 0.],\n",
       "         [0., 1., 0., 1., 0.],\n",
       "         [0., 1., 1., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0.],\n",
       "         [0., 0., 0., 1., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_mask = col_masks(patients, **options)\n",
    "col_mask.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ -0.       , -13.815511 ,  -0.       ,  -0.       ,\n",
       "            0.       ],\n",
       "         [-13.815511 ,  -0.       ,  -0.       ,  -0.       ,\n",
       "            0.       ],\n",
       "         [ -1.6094329,  -1.6094329,  -0.       ,  -0.       ,\n",
       "           -0.       ]],\n",
       "\n",
       "        [[ -0.       ,  -0.       ,  -0.       ,  -0.       ,\n",
       "            0.       ],\n",
       "         [ -0.       ,  -1.6094329,  -0.       ,  -0.       ,\n",
       "           -0.       ],\n",
       "         [ -0.       ,  -1.6094329,  -0.       ,  -0.       ,\n",
       "           -0.       ]],\n",
       "\n",
       "        [[ -0.       ,  -0.       ,  -0.       ,  -0.       ,\n",
       "           -0.       ],\n",
       "         [ -0.       ,  -0.       ,  -0.       ,  -0.       ,\n",
       "           -0.       ],\n",
       "         [ -0.       ,  -0.       ,  -0.       ,  -0.       ,\n",
       "           -0.       ]],\n",
       "\n",
       "        [[ -0.       ,  -0.       ,  -0.       ,  -0.       ,\n",
       "           -0.       ],\n",
       "         [ -0.       ,  -0.       ,  -0.       ,  -0.       ,\n",
       "           -0.       ],\n",
       "         [ -0.       ,  -0.       ,  -0.       ,  -0.       ,\n",
       "           -0.       ]]],\n",
       "\n",
       "\n",
       "       [[[ -0.       , -13.815511 ,  -0.       ,  -0.       ,\n",
       "            0.       ],\n",
       "         [ -0.       ,  -0.       ,  -0.       , -13.815511 ,\n",
       "            0.       ],\n",
       "         [ -0.       ,  -1.6094329,  -0.       ,  -1.6094329,\n",
       "           -0.       ]],\n",
       "\n",
       "        [[ -0.       ,  -0.       , -13.815511 , -13.815511 ,\n",
       "            0.       ],\n",
       "         [ -0.       , -13.815511 ,  -0.       , -13.815511 ,\n",
       "            0.       ],\n",
       "         [ -0.       , -13.815511 , -13.815511 ,  -0.       ,\n",
       "            0.       ]],\n",
       "\n",
       "        [[ -0.       ,  -0.       ,  -0.       ,  -0.       ,\n",
       "            0.       ],\n",
       "         [ -0.       ,  -0.       ,  -0.       ,  -1.6094329,\n",
       "           -0.       ],\n",
       "         [ -0.       ,  -0.       ,  -0.       ,  -1.6094329,\n",
       "           -0.       ]],\n",
       "\n",
       "        [[ -0.       ,  -0.       ,  -0.       ,  -0.       ,\n",
       "           -0.       ],\n",
       "         [ -0.       ,  -0.       ,  -0.       ,  -0.       ,\n",
       "           -0.       ],\n",
       "         [ -0.       ,  -0.       ,  -0.       ,  -0.       ,\n",
       "           -0.       ]]]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mask p_i_i before dividing by number of visits to save computations\n",
    "non_norm_summands = tf.multiply(log_p_j_i, col_mask)\n",
    "non_norm_summands.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-0.        , -6.9077554 , -0.        , -0.        ,\n",
       "           0.        ],\n",
       "         [-6.9077554 , -0.        , -0.        , -0.        ,\n",
       "           0.        ],\n",
       "         [-0.80471647, -0.80471647, -0.        , -0.        ,\n",
       "          -0.        ]],\n",
       "\n",
       "        [[-0.        , -0.        , -0.        , -0.        ,\n",
       "           0.        ],\n",
       "         [-0.        , -0.80471647, -0.        , -0.        ,\n",
       "          -0.        ],\n",
       "         [-0.        , -0.80471647, -0.        , -0.        ,\n",
       "          -0.        ]],\n",
       "\n",
       "        [[-0.        , -0.        , -0.        , -0.        ,\n",
       "          -0.        ],\n",
       "         [-0.        , -0.        , -0.        , -0.        ,\n",
       "          -0.        ],\n",
       "         [-0.        , -0.        , -0.        , -0.        ,\n",
       "          -0.        ]],\n",
       "\n",
       "        [[-0.        , -0.        , -0.        , -0.        ,\n",
       "          -0.        ],\n",
       "         [-0.        , -0.        , -0.        , -0.        ,\n",
       "          -0.        ],\n",
       "         [-0.        , -0.        , -0.        , -0.        ,\n",
       "          -0.        ]]],\n",
       "\n",
       "\n",
       "       [[[-0.        , -4.6051702 , -0.        , -0.        ,\n",
       "           0.        ],\n",
       "         [-0.        , -0.        , -0.        , -4.6051702 ,\n",
       "           0.        ],\n",
       "         [-0.        , -0.5364776 , -0.        , -0.5364776 ,\n",
       "          -0.        ]],\n",
       "\n",
       "        [[-0.        , -0.        , -4.6051702 , -4.6051702 ,\n",
       "           0.        ],\n",
       "         [-0.        , -4.6051702 , -0.        , -4.6051702 ,\n",
       "           0.        ],\n",
       "         [-0.        , -4.6051702 , -4.6051702 , -0.        ,\n",
       "           0.        ]],\n",
       "\n",
       "        [[-0.        , -0.        , -0.        , -0.        ,\n",
       "           0.        ],\n",
       "         [-0.        , -0.        , -0.        , -0.5364776 ,\n",
       "          -0.        ],\n",
       "         [-0.        , -0.        , -0.        , -0.5364776 ,\n",
       "          -0.        ]],\n",
       "\n",
       "        [[-0.        , -0.        , -0.        , -0.        ,\n",
       "          -0.        ],\n",
       "         [-0.        , -0.        , -0.        , -0.        ,\n",
       "          -0.        ],\n",
       "         [-0.        , -0.        , -0.        , -0.        ,\n",
       "          -0.        ]]]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now for each patient divide by number of real visits of that patient\n",
    "# Mask rows corresponding to NA ICDs afterward to ensure patient-by-patient division\n",
    "summands_w_dummies = non_norm_summands / tf.reshape(patients_ts, [2,1,1,1])\n",
    "summands_w_dummies.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.       , -6.9077554, -0.       , -0.       ,  0.       ],\n",
       "       [-6.9077554, -0.       , -0.       , -0.       ,  0.       ],\n",
       "       [-0.       , -0.       , -0.       , -0.       ,  0.       ],\n",
       "       [-0.       , -4.6051702, -0.       , -0.       ,  0.       ],\n",
       "       [-0.       , -0.       , -0.       , -4.6051702,  0.       ],\n",
       "       [-0.       , -0.       , -4.6051702, -4.6051702,  0.       ],\n",
       "       [-0.       , -4.6051702, -0.       , -4.6051702,  0.       ],\n",
       "       [-0.       , -4.6051702, -4.6051702, -0.       ,  0.       ],\n",
       "       [-0.       , -0.       , -0.       , -0.       ,  0.       ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summands = tf.boolean_mask(summands_w_dummies, row_masks)\n",
    "summands.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.9077554, -6.9077554,  0.       , -4.6051702, -4.6051702,\n",
       "       -9.2103405, -9.2103405, -9.2103405,  0.       ], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes_cost_per_visit = tf.reduce_sum(summands, -1)\n",
    "codes_cost_per_visit.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.6285415"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes_cost = tf.reduce_mean(codes_cost_per_visit)\n",
    "codes_cost.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That's the code-level cost function. Now for the visits level cost function.\n",
    "\n",
    "$\\frac{1}{T}\\sum\\limits_{t=1}^T\\sum\\limits_{-w\\leq i\\leq w}-x_{t+i}^T\\log{\\hat{y_t}}+(1-x_{t+i})^T\\log{(1-\\hat{y_t})}$\n",
    "\n",
    "Where $w$ is a pre-defined window of visits and\n",
    "\n",
    "$\\hat{y_t} = \\frac{\\exp{(W_sv_t+b_s)}}{\\sum\\limits_{j=1}^{|C|}\\exp(W_{sj}v_t+b_{sj})}$\n",
    "\n",
    "Where $W_{sj}$ is the $j^{th}$ row of $W_s$ and $b_{sj}$ is the $j^{th}$ element of $b_s$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., 1., 0.],\n",
       "        [0., 1., 1., 1., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ts = tf.reduce_sum(patients, -2)\n",
    "x_ts.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 1., 0., 0., 0.],\n",
       "        [0., 2., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 5., 0., 5., 0.],\n",
       "        [0., 6., 6., 6., 0.],\n",
       "        [0., 0., 0., 7., 0.],\n",
       "        [0., 0., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys = tf.multiply(x_ts, np.array([[1,2,3,4],[5,6,7,8]]).reshape([2,4,1]))\n",
    "ys.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0., 0., 0.],\n",
       "       [0., 2., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 5., 0., 5., 0.],\n",
       "       [0., 6., 6., 6., 0.],\n",
       "       [0., 0., 0., 7., 0.],\n",
       "       [0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_2d = tf.reshape(ys, [8,5])\n",
    "y_2d.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 1., 0.],\n",
       "       [0., 1., 1., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2d = x_ts.eval().reshape([8,5])\n",
    "x_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "win = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer = np.zeros([win, options['n_codes']])\n",
    "buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [1., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 1., 0.],\n",
       "       [0., 1., 1., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_buff = np.vstack([buffer, x_2d, buffer])\n",
    "x_buff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0., 0.],\n",
       "       [1., 3., 0., 1., 0.],\n",
       "       [0., 3., 1., 2., 0.],\n",
       "       [0., 1., 1., 2., 0.],\n",
       "       [0., 1., 0., 2., 0.],\n",
       "       [0., 2., 1., 2., 0.],\n",
       "       [0., 1., 1., 2., 0.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "win_start = 2 * win\n",
    "win_width = y_2d.shape[0]\n",
    "total = np.zeros(x_2d.shape)\n",
    "while win_start >= 0:\n",
    "    if win_start != win:\n",
    "        total += x_buff[win_start:win_start + win_width,:]\n",
    "    win_start -= 1\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now the same thing in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [1., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 1., 0.],\n",
       "       [0., 1., 1., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2d = tf.constant(x_2d)\n",
    "\n",
    "paddings = tf.constant([[win, win], [0, 0]])\n",
    "x_buff = tf.pad(x_2d, paddings, \"CONSTANT\")\n",
    "x_buff.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_ops(win_start, total):\n",
    "    \"\"\"Slide window function.\n",
    "    \n",
    "    Add x_ts from surrounding visits together before\n",
    "    taking the dot product with log(\\hat{y}).\n",
    "    \n",
    "    For passing to tf.while_loop\n",
    "    \"\"\"\n",
    "    summand = tf.slice(x_buff, [win_start, 0], total.shape)\n",
    "    return (win_start -1, tf.add(total, summand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# win corresponds to the variable w in the summation bounds  in eqn.\n",
    "# (2) of https://www.kdd.org/kdd2016/papers/files/rpp0303-choiA.pdf\n",
    "win = 2 \n",
    "win_start = 2 * win\n",
    "win_height = y_2d.shape[0] # (Number of patients) * max_t\n",
    "total = tf.zeros(x_2d.shape)\n",
    "loop_cond = lambda win_start, total: tf.less(-1, win_start)\n",
    "loop_fn = lambda win_start, total: loop_ops(win_start, total)\n",
    "_, window_x_total = tf.while_loop(loop_cond, loop_ops, (win_start, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0., 0.],\n",
       "       [1., 3., 0., 1., 0.],\n",
       "       [0., 3., 1., 2., 0.],\n",
       "       [0., 1., 1., 2., 0.],\n",
       "       [0., 1., 0., 2., 0.],\n",
       "       [0., 2., 1., 2., 0.],\n",
       "       [0., 1., 1., 2., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_x_total = tf.subtract(window_x_total, x_2d)\n",
    "correct_x_total.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That only sort of works...You'd get overlaps between patients visits. Redo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., 1., 0.],\n",
       "        [0., 1., 1., 1., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ts.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 1., 0.],\n",
       "        [0., 1., 1., 1., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pad = tf.pad(x_ts, [[0,0],[win, win], [0, 0]])\n",
    "x_pad.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The zeros below represent not only rows corresponding to padding,\n",
    "# but also to dummy visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 1., 1., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visit_mask = tf.reshape(tf.minimum(tf.reduce_sum(x_pad, -1), 1), x_pad.shape[:-1])\n",
    "visit_mask.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_ts = tf.constant(patients_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.5       , 0.5       , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.5       , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.33333334, 0.        , 0.33333334, 0.        ],\n",
       "        [0.        , 0.33333334, 0.33333334, 0.33333334, 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.33333334, 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normed_x_pad = x_pad / tf.reshape(patients_ts, [2,1,1])\n",
    "normed_x_pad.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.5       , 0.5       , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.5       , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.33333334, 0.        , 0.33333334, 0.        ],\n",
       "       [0.        , 0.33333334, 0.33333334, 0.33333334, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.33333334, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normed_x_pad_2d = tf.reshape(normed_x_pad, [-1, options['n_codes']])\n",
    "normed_x_pad_2d.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 1., 1., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visit_mask.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0., 0., 0.],\n",
       "       [0., 2., 0., 0., 0.],\n",
       "       [0., 5., 0., 5., 0.],\n",
       "       [0., 6., 6., 6., 0.],\n",
       "       [0., 0., 0., 7., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The zero rows wouldn't be there, because the above method\n",
    "# means x didn't need to have zero rows in this branch--only\n",
    "# for the Codes cost branch.\n",
    "y_2d = tf.constant(y_2d.eval()[[0,1,4,5,6]])\n",
    "y_2d.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_double_pad = tf.pad(normed_x_pad_2d, [[win, win], [0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changed x_buff to normed_x_pad_2d\n",
    "def loop_ops(win_start, total):\n",
    "    \"\"\"Slide window function.\n",
    "    \n",
    "    Add x_ts from surrounding visits together before\n",
    "    taking the dot product with log(\\hat{y}).\n",
    "    \n",
    "    For passing to tf.while_loop\n",
    "    \"\"\"\n",
    "    summand = tf.slice(x_double_pad, [win_start, 0], normed_x_pad_2d.shape)\n",
    "    print(summand)\n",
    "    return (win_start - 1, tf.add(total, summand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"while_18/Slice:0\", shape=(16, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Changed x_2d to normed_x_pad_2d. y_2d doesn't change\n",
    "\n",
    "# win corresponds to the variable w in the summation bounds  in eqn.\n",
    "# (2) of https://www.kdd.org/kdd2016/papers/files/rpp0303-choiA.pdf\n",
    "win = 2 \n",
    "win_start = 2 * win\n",
    "total = tf.zeros(normed_x_pad_2d.shape)\n",
    "loop_cond = lambda win_start, total: tf.less(-1, win_start)\n",
    "loop_fn = lambda win_start, total: loop_ops(win_start, total)\n",
    "_, window_x_total = tf.while_loop(loop_cond, loop_ops, (win_start, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.5       , 0.        , 0.        , 0.        ],\n",
       "       [0.5       , 1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.5       , 1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.5       , 1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.5       , 1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.5       , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.33333334, 0.        , 0.33333334, 0.        ],\n",
       "       [0.        , 0.6666667 , 0.33333334, 0.6666667 , 0.        ],\n",
       "       [0.        , 0.6666667 , 0.33333334, 1.        , 0.        ],\n",
       "       [0.        , 0.6666667 , 0.33333334, 1.        , 0.        ],\n",
       "       [0.        , 0.6666667 , 0.33333334, 1.        , 0.        ],\n",
       "       [0.        , 0.33333334, 0.33333334, 0.6666667 , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.33333334, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_x_total.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.5       , 0.        , 0.        , 0.        ],\n",
       "       [0.5       , 1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.5       , 0.        , 0.        , 0.        ],\n",
       "       [0.5       , 0.5       , 0.        , 0.        , 0.        ],\n",
       "       [0.5       , 1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.5       , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.33333334, 0.        , 0.33333334, 0.        ],\n",
       "       [0.        , 0.6666667 , 0.33333334, 0.6666667 , 0.        ],\n",
       "       [0.        , 0.33333334, 0.33333334, 0.6666666 , 0.        ],\n",
       "       [0.        , 0.33333334, 0.        , 0.6666666 , 0.        ],\n",
       "       [0.        , 0.6666667 , 0.33333334, 0.6666666 , 0.        ],\n",
       "       [0.        , 0.33333334, 0.33333334, 0.6666667 , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.33333334, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtract out x_{t+0}\n",
    "correct_x_totals_pad = tf.subtract(window_x_total, normed_x_pad_2d)\n",
    "correct_x_totals_pad.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visit_mask = tf.reshape(visit_mask, [-1,])\n",
    "visit_mask.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.5       , 0.        , 0.        , 0.        ],\n",
       "       [0.5       , 0.5       , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.33333334, 0.33333334, 0.6666666 , 0.        ],\n",
       "       [0.        , 0.33333334, 0.        , 0.6666666 , 0.        ],\n",
       "       [0.        , 0.6666667 , 0.33333334, 0.6666666 , 0.        ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_x_total = tf.boolean_mask(correct_x_totals_pad, visit_mask)\n",
    "final_x_total.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
